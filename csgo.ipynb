{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Corbin\\AppData\\Local\\Temp\\ipykernel_22896\\2507049015.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  economy_data = pd.read_csv('data/economy.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "economy_data = pd.read_csv('data/economy.csv')\n",
    "picks_data = pd.read_csv('data/picks.csv')\n",
    "players_data = pd.read_csv('data/players.csv')\n",
    "results_data = pd.read_csv('data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(results_data, picks_data, on=['date', 'match_id', 'team_1', 'team_2'])\n",
    "\n",
    "# print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# verify that we have no missing/null data in columns\n",
    "missing_data = merged_data.isnull().sum()\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'team_1', 'team_2', '_map', 'best_of', 't1_removed_1',\n",
      "       't1_removed_2', 't1_removed_3', 't2_removed_1', 't2_removed_2',\n",
      "       't2_removed_3', 't1_picked_1', 't2_picked_1', 'left_over'],\n",
      "      dtype='object')\n",
      "date:\n",
      "0    2020-03-18\n",
      "1    2020-03-18\n",
      "2    2020-03-18\n",
      "3    2020-03-17\n",
      "4    2020-03-17\n",
      "Name: date, dtype: object\n",
      "\n",
      "team_1:\n",
      "0    New England Whalers\n",
      "1                Rugratz\n",
      "2                Rugratz\n",
      "3            Singularity\n",
      "4            Singularity\n",
      "Name: team_1, dtype: object\n",
      "\n",
      "team_2:\n",
      "0          Station7\n",
      "1    Bad News Bears\n",
      "2    Bad News Bears\n",
      "3          Endpoint\n",
      "4          Endpoint\n",
      "Name: team_2, dtype: object\n",
      "\n",
      "_map:\n",
      "0     Inferno\n",
      "1     Inferno\n",
      "2     Vertigo\n",
      "3    Overpass\n",
      "4     Vertigo\n",
      "Name: _map, dtype: object\n",
      "\n",
      "best_of:\n",
      "0    1\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "4    3\n",
      "Name: best_of, dtype: object\n",
      "\n",
      "t1_removed_1:\n",
      "0    Mirage\n",
      "1     Dust2\n",
      "2     Dust2\n",
      "3     Train\n",
      "4     Train\n",
      "Name: t1_removed_1, dtype: object\n",
      "\n",
      "t1_removed_2:\n",
      "0     Dust2\n",
      "1      Nuke\n",
      "2      Nuke\n",
      "3    Mirage\n",
      "4    Mirage\n",
      "Name: t1_removed_2, dtype: object\n",
      "\n",
      "t1_removed_3:\n",
      "0    Vertigo\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "Name: t1_removed_3, dtype: object\n",
      "\n",
      "t2_removed_1:\n",
      "0      Nuke\n",
      "1    Mirage\n",
      "2    Mirage\n",
      "3      Nuke\n",
      "4      Nuke\n",
      "Name: t2_removed_1, dtype: object\n",
      "\n",
      "t2_removed_2:\n",
      "0      Train\n",
      "1      Train\n",
      "2      Train\n",
      "3    Inferno\n",
      "4    Inferno\n",
      "Name: t2_removed_2, dtype: object\n",
      "\n",
      "t2_removed_3:\n",
      "0    Overpass\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "Name: t2_removed_3, dtype: object\n",
      "\n",
      "t1_picked_1:\n",
      "0         0.0\n",
      "1     Vertigo\n",
      "2     Vertigo\n",
      "3    Overpass\n",
      "4    Overpass\n",
      "Name: t1_picked_1, dtype: object\n",
      "\n",
      "t2_picked_1:\n",
      "0        0.0\n",
      "1    Inferno\n",
      "2    Inferno\n",
      "3    Vertigo\n",
      "4    Vertigo\n",
      "Name: t2_picked_1, dtype: object\n",
      "\n",
      "left_over:\n",
      "0     Inferno\n",
      "1    Overpass\n",
      "2    Overpass\n",
      "3       Dust2\n",
      "4       Dust2\n",
      "Name: left_over, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find all the columns which may be problematic while training a model\n",
    "object_columns = merged_data.dtypes[merged_data.dtypes == 'object'].index\n",
    "print(object_columns)\n",
    "for column in object_columns:\n",
    "    print(f\"{column}:\\n{merged_data[column].head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "team_encoder = LabelEncoder()\n",
    "unique_teams = list(set(np.concatenate((merged_data['team_1'].unique(), merged_data['team_2'].unique()), axis=None)))\n",
    "team_encoder.fit(unique_teams)\n",
    "\n",
    "merged_data['team_1'] = team_encoder.transform(merged_data['team_1'])\n",
    "merged_data['team_2'] = team_encoder.transform(merged_data['team_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical variables\n",
    "# these are the string/id columns\n",
    "# use one-hot encoding for _map because there aren't many unique values\n",
    "# use ordinal encoding for team_1 and team_2 to avoid increasing dimensionality too much\n",
    "\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# encoder = OrdinalEncoder()\n",
    "# merged_data[['team_1', 'team_2']] = encoder.fit_transform(merged_data[['team_1', 'team_2']])\n",
    "\n",
    "# For _map column, we can use one-hot encoding as before\n",
    "merged_data = pd.get_dummies(merged_data, columns=['_map', 'best_of', 't1_removed_1', 't1_removed_2', 't1_removed_3',\n",
    "       't2_removed_1', 't2_removed_2', 't2_removed_3', 't1_picked_1',\n",
    "       't2_picked_1', 'left_over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_date_to_ordinal(date):\n",
    "    return datetime.strptime(date, \"%Y-%m-%d\").toordinal()\n",
    "\n",
    "# Convert the date column to a numeric format\n",
    "merged_data['date'] = merged_data['date'].apply(convert_date_to_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# ensure there are no categorical variables left, which would fail our model\n",
    "object_columns = merged_data.dtypes[merged_data.dtypes == 'object'].index\n",
    "print(object_columns)\n",
    "for column in object_columns:\n",
    "    print(f\"{column}:\\n{merged_data[column].head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We'll try to predict the 'match_winner' column\n",
    "X = merged_data.drop('match_winner', axis=1)\n",
    "y = merged_data['match_winner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on logistic regression and get the accuracy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.6557436082102989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65      1470\n",
      "           2       0.62      0.70      0.66      1307\n",
      "\n",
      "    accuracy                           0.66      2777\n",
      "   macro avg       0.66      0.66      0.66      2777\n",
      "weighted avg       0.66      0.66      0.66      2777\n",
      "\n",
      "ROC-AUC: 0.6584560373499055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Model accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Corbin\\Documents\\dev\\minlab-learn-ml\\env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Corbin\\Documents\\dev\\minlab-learn-ml\\env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The team with the highest prediction accuracy is ex-eUnited with an accuracy of 1.0 over 7 games\n"
     ]
    }
   ],
   "source": [
    "# figure out which team we predicted most accurately for\n",
    "y_all = model.predict(X)\n",
    "data_with_preds = merged_data.copy()\n",
    "data_with_preds['predictions'] = y_all\n",
    "data_with_preds['team_1'] = team_encoder.inverse_transform(data_with_preds[['team_1']])\n",
    "data_with_preds['team_2'] = team_encoder.inverse_transform(data_with_preds[['team_2']])\n",
    "\n",
    "team_accuracies = {}\n",
    "teams = pd.concat([data_with_preds['team_1'], data_with_preds['team_2']]).unique()\n",
    "\n",
    "for team in teams:\n",
    "    team_games = data_with_preds[(data_with_preds['team_1'] == team) | (data_with_preds['team_2'] == team)]\n",
    "    if len(team_games) < 5:\n",
    "        continue\n",
    "    correct_predictions = team_games[team_games['match_winner'] == team_games['predictions']]\n",
    "    accuracy = len(correct_predictions) / len(team_games)\n",
    "    team_accuracies[team] = accuracy\n",
    "\n",
    "best_team = max(team_accuracies, key=team_accuracies.get)\n",
    "num_best_team_games = len(data_with_preds[(data_with_preds['team_1'] == best_team) | (data_with_preds['team_2'] == best_team)])\n",
    "print(f'The team with the highest prediction accuracy is {best_team} with an accuracy of {team_accuracies[best_team]} over {num_best_team_games} games')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
